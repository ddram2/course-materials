---
created: 2026.02.18
MOC1: MOC.10.edu.교과_콘텐츠
MOC2a: MOC.60.mthd.통계
MOC2b: ""
source:
tags:
  - 교육/강의
  - 환경보건
  - 연구
  - 교육
  - 노트
---
**# Session 4. 기조발제 — AI 시대, 세 가지 불편한 질문

> 교수 발제 노트 | 세션 4 도입 (16:05–16:13, 약 8분)
> **톤**: 각 아젠다에 대해 "그럴듯한 반론(삐딱한 주장)"을 먼저 소개한다. 그 주장이 왜 매력적인지 인정하되, 어디서 문제가 될 수 있는지를 드러낸다. 답을 주지 않고, 패널과 청중이 스스로 선을 찾게 한다.

---

## 발제 취지

> 오늘 전반부에서 마크다운, Obsidian, AI IDE를 체험했습니다. 도구는 강력합니다. 그런데 그 강력한 도구를 앞에 두면, 이런 생각이 들 수 있습니다 — "이걸 왜 안 써?" 합리적이고, 솔직한 생각입니다. 지금부터 그런 주장 세 가지를 소개하고, 거기에 제가 좀 불편한 질문을 얹겠습니다. 정답은 없습니다. 여러분의 생각을 듣고 싶습니다.

---

## 아젠다 1. AI 산출물, 어디까지 용인할 수 있을까?

> 담당 패널: (배정 예정)

### 삐딱한 주장

> "연구제안서를 쓸 때, AI에게 논문 10편을 넣고 '문헌 고찰 초안을 써 줘'라고 했다. 결과물을 훑어 보니 꽤 괜찮다. 이걸 왜 처음부터 내가 써야 하나? 30% 정도 다듬어서 쓰면 되지 않나? 절약한 시간에 실험 설계나 데이터 분석처럼 더 중요한 일에 집중하는 게 효율적 아닌가?"
>
> "예전에는 AI가 hallucination이 심했다고 하지만, 지금은 많이 줄었다. 게다가 Windsurf 같은 IDE를 쓰면 파일을 직접 참조하니까 더 정확하다. 오류 가능성이 줄었으면, copy/paste해도 되는 거 아닌가?"

### 일리가 있다 — 하지만

솔직히 말해서, 이 주장엔 일리가 있다. AI의 정확도는 빠르게 개선되고 있고, 시간 효율도 사실이다.

하지만 이런 상황을 상상해 보자:

- AI가 정리해 준 선행연구 5편 중 2편이 **존재하지 않는 논문**이었다. 심사위원이 발견했다. — "몰랐다"는 변명이 될까?
- AI가 써준 문헌 고찰에서 OR = 0.85 (95% CI: 0.72–1.01)을 "유의한 보호 효과"라고 해석했다. 여러분이 그대로 제출했다. — 이것은 typo인가, **검증 부재**인가?
- "학술적 톤으로 다듬어 줘"라고 요청했더니 AI가 문장 구조, 어휘, 논리 연결까지 바꿨다. 이것은 문법 교정인가, 내용 생성인가?

서울대 가이드라인은 "AI 산출물을 **가공 없이 그대로** 넣는 것은 연구진실성 위반으로 평가될 수 있다"고 말한다 (제2장 3.(3)). 그리고 "**모든 책임은 본인**에게 있다" (제2장 1.(6)). — 그런데 **'가공'의 기준은 어디에도 없다.** 30% 수정하면 괜찮은가? 50%면? 그 선은 누가 긋는가?

### 질문을 던진다

> "AI가 점점 정확해지고 있는 것은 사실입니다. 그렇다면, 충분히 정확해진 AI의 산출물을 **그대로 쓰면 안 되는 이유**가 아직 있을까요? 있다면, 그것은 무엇입니까?"

---

## 아젠다 2. 과제·공부·연구에서 AI 활용, 어디까지 인정될 수 있을까?

> 담당 패널: (배정 예정)

### 삐딱한 주장

> "결국 내가 책임지는 건데, 왜 안 되나? 학위를 따고, 좋은 성적을 받는 게 목적이라면, **최선의 도구를 최적으로 쓰는 것이 현명한 거 아닌가?** 계산기가 나왔을 때도 '직접 계산해야 한다'고 했지만, 지금 누가 손으로 계산하나? AI도 마찬가지 아닌가?"
>
> "교수님은 '불편하고 반복적으로 체득해야 내 것이 된다'고 하시는데, 그건 AI 이전 시대의 논리 아닌가? AI 시대엔 **무엇을 체득할지** 자체가 달라져야 하는 거 아닌가?"

### 일리가 있다 — 하지만

이 주장도 틀린 말은 아니다. 도구의 진화에 맞게 역량의 정의가 바뀌는 것은 역사적으로 반복되어 왔다.

하지만 이런 상황을 상상해 보자:

- AI에게 "이 데이터로 다중 로지스틱 회귀분석을 해 줘"라고 요청해서 R 코드를 받았다. 코드는 실행되고 결과도 나온다. **논문심사에서 심사위원이 물었다: "왜 이 변수를 confounder로 보정했나요?"** — 대답하지 못했다. 결과는 있는데, 과정을 설명하지 못하는 연구자. 이것이 '역량'인가?
- 1학년 때부터 모든 과제를 AI와 함께 작성한 학생이, **종합시험에서 AI 없이 3시간 동안 직접 써야 했다.** 빈 화면 앞에서 첫 문장을 시작하는 데 40분이 걸렸다.

빨리 들어온 것은 빨리 날아가는 법이다. Cognitive Debt(인지부채) — AI가 대신해 준 만큼, 내가 체득하지 못한 것이 축적된다. 서울대 가이드라인은 "**비판적 사고 능력을 저하시키지 않도록 주의**"하라 (제1장 2.(2)), "**연구 설계와 해석은 인간 연구자가 주도**"해야 한다 (제2장 3.(6))고 말한다.

하지만 — 이것을 누가 확인하는가? AI로 쓴 과제가 A+를 받고, AI로 만든 코드로 논문이 통과되면 — **드러나지 않는다.** 드러나는 순간은 **질문을 받았을 때**, **혼자 해야 할 때**다.

### 질문을 던진다

> "계산기 비유가 맞다면, AI 시대에 '직접 해야만 하는 것'은 무엇이 남을까요? 아무것도 남지 않을까요? 아니면 오히려 더 중요해지는 것이 있을까요?"

---

## 아젠다 3. AI로 논문 쓰기 — 그 경계는 누가 정하는가?

> 담당 패널: (배정 예정)

### 삐딱한 주장

> "논문 대필이 안 되는 것처럼 AI가 쓴 논문도 안 된다고? 그런데 **그 경계가 모호하다.** AI에게 outline을 주고 초안을 받아서 70% 다시 쓰면 — 그건 내 논문인가, AI 논문인가? 영어 원어민 교정 서비스(proofreading)는 허용되는데, AI 교정은 왜 문제가 되나?"
>
> "Nature도 Science도 'AI 사용 시 공시하라'고 하지, 'AI를 쓰지 마라'고는 안 한다. **쓰되, 밝히면 되는 거 아닌가?**"

### 일리가 있다 — 하지만

맞다. 주요 저널도 AI 사용 자체를 금지하지 않는다. 투명하게 공시하라는 것이 현재의 합의다.

그런데 이런 상황을 상상해 보자:

- "AI를 Methods 작성에 활용했음"이라고 공시한 논문과, "AI를 Discussion 전체 초안 작성에 활용했음"이라고 공시한 논문 — 같은 수준의 공시인가? **어디에, 얼마나 쓴 것까지 밝혀야 하는가?**
- 동료 A는 자기가 쓴 초고를 AI에게 다듬게 했고, 동료 B는 AI에게 초안을 쓰게 한 뒤 자기가 다듬었다. 최종 결과물의 품질은 비슷하다. **둘의 차이는 무엇인가?** 하나는 허용이고 하나는 위반인가?

서울대 가이드라인 각주¹은 "오로지 외국어 표현의 교정 또는 문법 검토를 위해서만 AI를 활용할 경우… 연구 부정행위에 해당하는 것은 아니다"라고 말한다. 그런데 — **"학술적으로 다듬어 줘"가 '문법 교정'인지 '내용 생성'인지**, 그 판단을 누가 하는가?

결국 경계는 모호하다. 그리고 그 모호함 속에서, 각자가 자기만의 선을 긋고 있다 — **의식적으로든 무의식적으로든.**

### 질문을 던진다

> "AI 사용을 밝히면 된다고 합니다. 그렇다면, **여러분은 무엇을 밝히고 있습니까?** 그리고 그 선을 어떤 기준으로 정했습니까? — 그 기준이 명확하지 않다면, 그것은 괜찮은 건가요?"

---

## 전환 멘트 (패널로 넘기며)

> "세 가지 주장을 소개하고, 각각에 불편한 질문을 얹었습니다. 솔직히 저도 답이 명확하지 않습니다. 이제 패널 세 분이 각자 맡은 아젠다에 대해 생각을 들려주시겠습니다. 그 뒤에 여러분 모두의 이야기를 듣겠습니다."
